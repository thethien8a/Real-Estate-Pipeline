# ğŸ  BDS - Real Estate Data Warehouse with Delta Lake

Dá»± Ã¡n Data Warehouse chuyÃªn nghiá»‡p cho phÃ¢n tÃ­ch thá»‹ trÆ°á»ng báº¥t Ä‘á»™ng sáº£n, sá»­ dá»¥ng **Delta Lake** vÃ  kiáº¿n trÃºc Lakehouse hiá»‡n Ä‘áº¡i.

## â­ TÃ­nh nÄƒng ná»•i báº­t

- âœ… **Delta Lake Integration**: ACID transactions, Time Travel, Schema Evolution
- ğŸš€ **Concurrent Web Scraping**: Thu tháº­p dá»¯ liá»‡u song song vá»›i ThreadPoolExecutor
- ğŸ—ï¸ **Star Schema Design**: Fact & Dimension tables tá»‘i Æ°u cho phÃ¢n tÃ­ch
- ğŸ”„ **ETL Pipeline**: Raw â†’ Staging â†’ Warehouse vá»›i data quality checks
- ğŸ“Š **Time Series Analysis**: PhÃ¢n tÃ­ch xu hÆ°á»›ng giÃ¡ BÄS theo thá»i gian
- ğŸ” **Data Versioning**: Time Travel Ä‘á»ƒ audit vÃ  rollback

## ğŸ—ï¸ Kiáº¿n trÃºc dá»± Ã¡n

```
BDS/
â”œâ”€â”€ data/                          # Delta Lake Storage
â”‚   â”œâ”€â”€ raw/                       # ğŸ—„ï¸ Raw Layer (Delta Tables)
â”‚   â”‚   â””â”€â”€ batdongsan/            #    - Dá»¯ liá»‡u thÃ´ tá»« crawler
â”‚   â”‚       â”œâ”€â”€ _delta_log/        #    - Transaction logs
â”‚   â”‚       â””â”€â”€ *.parquet          #    - Parquet data files
â”‚   â”œâ”€â”€ staging/                   # ğŸ§¹ Staging Layer (Delta Tables)
â”‚   â”‚   â””â”€â”€ batdongsan_clean/      #    - Dá»¯ liá»‡u Ä‘Ã£ clean & normalize
â”‚   â””â”€â”€ warehouse/                 # ğŸ›ï¸ Warehouse Layer (Star Schema)
â”‚       â”œâ”€â”€ fact_listings/         #    - Fact: Listings
â”‚       â”œâ”€â”€ dim_location/          #    - Dimension: Locations
â”‚       â”œâ”€â”€ dim_property_type/     #    - Dimension: Property Types
â”‚       â””â”€â”€ dim_time/              #    - Dimension: Time
â”‚
â”œâ”€â”€ src/                           # Source Code
â”‚   â”œâ”€â”€ crawl_da_luong.py          # ğŸ•·ï¸ Concurrent web crawler
â”‚   â”œâ”€â”€ load/                      # ğŸ’¾ Delta Lake Manager
â”‚   â”‚   â””â”€â”€ delta_lake_manager.py  #    - CRUD operations cho Delta Tables
â”‚   â”œâ”€â”€ transform/                 # ğŸ”„ ETL Pipeline
â”‚   â”‚   â””â”€â”€ etl_pipeline.py        #    - Raw â†’ Staging â†’ Warehouse
â”‚   â”œâ”€â”€ examples/                  # ğŸ“š Demo & Examples
â”‚   â”‚   â””â”€â”€ delta_lake_demo.py     #    - Use cases & tutorials
â”‚   â””â”€â”€ utils/                     # ğŸ› ï¸ Utilities
â”‚
â”œâ”€â”€ documentation/                 # ğŸ“– Documentation
â”‚   â”œâ”€â”€ config/                    # Configurations
â”‚   â”œâ”€â”€ schemas/                   # Data schemas
â”‚   â””â”€â”€ guides/                    # Technical guides
â”‚
â”œâ”€â”€ notebooks/                     # ğŸ“Š Analysis Notebooks
â”œâ”€â”€ dags/                          # ğŸ”„ Airflow DAGs
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ¯ Kiáº¿n trÃºc Data Lakehouse (3 Layers)

### 1ï¸âƒ£ Raw Data Layer (`data/raw/`)
**Delta Table**: Dá»¯ liá»‡u thÃ´ tá»« web crawler
- âœ… **ACID Transactions**: Äáº£m báº£o tÃ­nh toÃ n váº¹n khi crawler cháº¡y song song
- ğŸ“¸ **Time Travel**: Truy cáº­p snapshot dá»¯ liá»‡u theo ngÃ y
- ğŸ”„ **Append-only**: Giá»¯ nguyÃªn lá»‹ch sá»­ thu tháº­p
- ğŸ“Š **Parquet Format**: Compressed columnar storage

**Dá»¯ liá»‡u**: Listings tá»« batdongsan.com.vn (title, price, area, location...)

### 2ï¸âƒ£ Staging Layer (`data/staging/`)
**Delta Table**: Dá»¯ liá»‡u Ä‘Ã£ clean & normalize
- ğŸ§¹ **Data Cleaning**: Loáº¡i bá» duplicate, null values
- ğŸ”¢ **Normalization**: Parse giÃ¡ (tá»·/triá»‡u â†’ VND), diá»‡n tÃ­ch (text â†’ mÂ²)
- âœ‚ï¸ **Deduplication**: Loáº¡i bá» duplicate theo `Link tin`
- âœ… **Schema Enforcement**: Äáº£m báº£o data quality

**Transform**: Raw â†’ Staging (lÃ m sáº¡ch + chuáº©n hÃ³a)

### 3ï¸âƒ£ Warehouse Layer (`data/warehouse/`)
**Star Schema**: Fact & Dimension tables
- ğŸŒŸ **Fact Table**: `fact_listings` (measures: price, area, etc.)
- ğŸ“ **Dim Location**: Äá»‹a Ä‘iá»ƒm (Quáº­n/Huyá»‡n/TP)
- ğŸ˜ï¸ **Dim Property Type**: Loáº¡i BÄS (NhÃ , CÄƒn há»™, Äáº¥t...)
- ğŸ“… **Dim Time**: Thá»i gian Ä‘Äƒng tin
- ğŸ”„ **Upsert Support**: Update giÃ¡, status khi cÃ³ thay Ä‘á»•i

**Transform**: Staging â†’ Warehouse (Star Schema modeling)

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **Storage Format**: Delta Lake 3.0+ (ACID, Time Travel)
- **Processing Engine**: Apache Spark 3.5+ (PySpark)
- **Data Format**: Parquet (Columnar, Compressed)
- **Web Scraping**: Selenium + BeautifulSoup + Requests
- **Concurrency**: Python ThreadPoolExecutor

### Data Pipeline
- **ETL Framework**: Custom Python + Apache Airflow (planned)
- **Data Modeling**: Star Schema (Kimball methodology)
- **Language**: Python 3.9+
- **Libraries**: Pandas, NumPy, Delta-Spark

### Infrastructure
- **Version Control**: Git + GitHub
- **CI/CD**: GitHub Actions
- **Documentation**: Markdown + Jupyter Notebooks

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Clone repository
git clone https://github.com/thethien8a/Real-Estate.git
cd BDS

# Táº¡o virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate.bat

# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Cháº¡y Web Crawler (Thu tháº­p dá»¯ liá»‡u)

```bash
# Cháº¡y crawler vá»›i Delta Lake
python src/crawl_da_luong.py
```

**Cáº¥u hÃ¬nh trong file** (`src/crawl_da_luong.py`):
```python
START_PAGE = 1          # Trang báº¯t Ä‘áº§u
END_PAGE = 10           # Trang káº¿t thÃºc
CRAWL_DETAILS = True    # Crawl chi tiáº¿t tin
USE_DELTA_LAKE = True   # LÆ°u vÃ o Delta Lake
MAX_WORKERS = 4         # Sá»‘ thread song song
```

**Output**:
- âœ… CSV backup: `batdongsan_YYYYMMDD_HHMMSS.csv`
- âœ… Delta Lake: `data/raw/batdongsan/`

### 3. Cháº¡y ETL Pipeline (Transform dá»¯ liá»‡u)

```bash
# Full pipeline: Raw â†’ Staging â†’ Warehouse
python src/transform/etl_pipeline.py
```

**Pipeline thá»±c hiá»‡n**:
1. Deduplicate Raw data
2. Transform Raw â†’ Staging (clean + normalize)
3. Transform Staging â†’ Warehouse (Star Schema)
4. Update expired listings

### 4. Demo & Examples

```bash
# Basic operations
python -c "from src.examples.delta_lake_demo import demo_basic_operations; demo_basic_operations()"

# ETL Pipeline demo
python -c "from src.examples.delta_lake_demo import demo_etl_pipeline; demo_etl_pipeline()"

# Upsert demo
python -c "from src.examples.delta_lake_demo import demo_upsert; demo_upsert()"

# Time Travel demo
python -c "from src.examples.delta_lake_demo import demo_time_travel; demo_time_travel()"
```

## ï¿½ Use Cases & Code Examples

### ğŸ”¹ 1. LÆ°u dá»¯ liá»‡u vÃ o Delta Lake

```python
from src.load.delta_lake_manager import quick_save_raw
import pandas as pd

# Sau khi crawler xong
df = pd.DataFrame(data)
quick_save_raw(df)  # Tá»± Ä‘á»™ng lÆ°u vÃ o data/raw/batdongsan/
```

### ğŸ”¹ 2. Äá»c dá»¯ liá»‡u tá»« Delta Lake

```python
from src.load.delta_lake_manager import quick_read_raw

# Äá»c version má»›i nháº¥t
df = quick_read_raw()

# Time Travel: Äá»c version cÅ©
df_v1 = quick_read_raw(version=1)

# Äá»c theo timestamp
df_yesterday = quick_read_raw(timestamp="2025-10-12 14:30:00")
```

### ğŸ”¹ 3. Cháº¡y ETL Pipeline

```python
from src.transform.etl_pipeline import run_etl_pipeline

# Full pipeline: Raw â†’ Staging â†’ Warehouse
run_etl_pipeline()
```

### ğŸ”¹ 4. Update/Upsert dá»¯ liá»‡u

```python
from src.load.delta_lake_manager import DeltaLakeManager

manager = DeltaLakeManager()

# Update expired listings
manager.update_expired_listings()

# Upsert new data
new_df = pd.DataFrame({...})
manager.upsert_listings(new_df, merge_key="Link tin")

manager.stop_spark()
```

### ï¿½ 5. Xem lá»‹ch sá»­ thay Ä‘á»•i

```python
from src.load.delta_lake_manager import DeltaLakeManager

manager = DeltaLakeManager()
history = manager.get_table_history("raw")
print(history[["version", "timestamp", "operation"]])
manager.stop_spark()
```

## ğŸ“‹ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Scraping   â”‚  batdongsan.com.vn
â”‚  (Concurrent)   â”‚  â†’ ThreadPoolExecutor (4 workers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAW LAYER     â”‚  Delta Table
â”‚  (Append only)  â”‚  â†’ ACID, Time Travel
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  deduplicate
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGING LAYER   â”‚  Delta Table  
â”‚ (Clean + Norm)  â”‚  â†’ Parse price/area, remove nulls
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚  star schema modeling
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WAREHOUSE LAYER â”‚  Delta Tables (Star Schema)
â”‚  (Analytics)    â”‚  â†’ Fact + Dimensions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    ğŸ“Š BI Tools / Analysis
```

## ğŸ¯ TÃ­nh nÄƒng Delta Lake trong dá»± Ã¡n

| TÃ­nh nÄƒng | Use Case | Lá»£i Ã­ch |
|-----------|----------|---------|
| **ACID Transactions** | Crawler cháº¡y song song | KhÃ´ng bá»‹ corrupt data |
| **Time Travel** | So sÃ¡nh giÃ¡ theo ngÃ y | `df = read_raw_data(version=1)` |
| **Schema Evolution** | Website thay Ä‘á»•i cáº¥u trÃºc | Tá»± Ä‘á»™ng adapt schema má»›i |
| **Upsert** | Update giÃ¡ BÄS | `upsert_listings(new_df)` |
| **Deduplication** | Loáº¡i bá» tin trÃ¹ng | `deduplicate_raw_data()` |
| **Compaction** | Tá»‘i Æ°u storage | `optimize_table("raw")` |
| **Vacuum** | XÃ³a file cÅ© | `vacuum_table(retention=168h)` |

## ğŸ“š Documentation

- [Delta Lake Architecture](./documentation/guides/delta-lake.md)
- [ETL Pipeline Design](./documentation/guides/etl-pipeline.md)
- [Data Schema](./documentation/schemas/)
- [API Reference](./documentation/guides/api.md)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

- **Author**: thethien8a
- **Repository**: [Real-Estate](https://github.com/thethien8a/Real-Estate)
- **Issues**: [GitHub Issues](https://github.com/thethien8a/Real-Estate/issues)

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork dá»± Ã¡n
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.
